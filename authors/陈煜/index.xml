<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>陈煜 | AIBluefisher</title>
    <link>https://AIBluefisher.github.io/authors/%E9%99%88%E7%85%9C/</link>
      <atom:link href="https://AIBluefisher.github.io/authors/%E9%99%88%E7%85%9C/index.xml" rel="self" type="application/rss+xml" />
    <description>陈煜</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2020</copyright><lastBuildDate>Thu, 05 Mar 2020 00:09:33 +0800</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>陈煜</title>
      <link>https://AIBluefisher.github.io/authors/%E9%99%88%E7%85%9C/</link>
    </image>
    
    <item>
      <title>大规模场景下的运动恢复结构算法 (Master Thesis)</title>
      <link>https://AIBluefisher.github.io/publication/ms-thesis/</link>
      <pubDate>Thu, 05 Mar 2020 00:09:33 +0800</pubDate>
      <guid>https://AIBluefisher.github.io/publication/ms-thesis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Robust Optimization in 3D Vision</title>
      <link>https://AIBluefisher.github.io/post/optimization/</link>
      <pubDate>Sun, 28 Jul 2019 11:02:09 +0800</pubDate>
      <guid>https://AIBluefisher.github.io/post/optimization/</guid>
      <description>&lt;h2 id=&#34;1-凸优化和非凸优化&#34;&gt;1. 凸优化和非凸优化&lt;/h2&gt;
&lt;p&gt;凸优化问题的一般形式&lt;/p&gt;
&lt;p&gt;$$
\min\quad f(x) \qquad\qquad\qquad\qquad \&lt;br&gt;
s.t.\quad h_i(x) = 0, \forall i = 1,\cdots, n\&lt;br&gt;
\qquad\quad g_j(x) &amp;lt; 0, \forall j = 1, \cdots, m
\tag{1}
$$
其中 $f(x), g_j(x)$ 都是凸函数，$h_i(x)$ 为仿射函数(既是凸函数又是凹函数)。&lt;/p&gt;
&lt;h3 id=&#34;11-凸函数&#34;&gt;1.1 凸函数&lt;/h3&gt;
&lt;p&gt;凸函数的定义:
对于定义在凸集上的函数$f$，如果对任意 $0 \leq \theta \leq 1$，都有&lt;/p&gt;
&lt;p&gt;$$
f(\theta x + (1 - \theta) y) \leq \theta f(x) + (1 - \theta) f(y) \tag{2}
$$&lt;/p&gt;
&lt;p&gt;一个简单的例子: 对于下图，函数任意两点之间的弦都在函数的上方。&lt;/p&gt;
&lt;div align=center&gt; 
    &lt;img src=&#34;https://AIBluefisher.github.io/img/optimization/convex_function.png&#34; /&gt;
&lt;/div&gt;
&lt;!-- 以及更高维空间中的凸函数

&lt;div align=center&gt;
    &lt;img src=&#34;https://AIBluefisher.github.io/img/optimization/3d_convex_function.jpg&#34;/&gt;
&lt;/div&gt; --&gt;
&lt;p&gt;但是实际中，要验证一个函数是否是凸函数，这个定义很不好用。因此，存在一些其他方法判断是否是凸函数。&lt;/p&gt;
&lt;h4 id=&#34;1-导数和二阶信息判断&#34;&gt;(1) 导数和二阶信息判断&lt;/h4&gt;
&lt;p&gt;对于一个光滑的函数(几乎处处可导)，可通过以下导数信息判断:&lt;/p&gt;
&lt;p&gt;(一阶充要条件) $f(y) \geq f(x) + \nabla f(x)^T (y - x)$
(二阶充要条件) $\nabla^2 f(x) \geq 0$&lt;/p&gt;
&lt;h4 id=&#34;2-利用凸函数的结构叠加性质&#34;&gt;(2) 利用凸函数的结构叠加性质&lt;/h4&gt;
&lt;p&gt;另一类有用的方法就是可以利用凸函数的一些结构叠加性质来判断这些函数是否是凸函数复合而成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;非负加权求和: $f(x) = \sum_i \alpha_if_i(x), \forall \alpha_i \geq 0$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;仿射变换: $f(x) = f_i(Ax + b)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;取最大值: $f(x) = max{f_1(x), \cdots, f_m(x)}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;标量复合, 向量复合, 最小化 &amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12-非凸函数&#34;&gt;1.2 非凸函数&lt;/h3&gt;
&lt;p&gt;凸函数(凹函数，拟凸函数)的一个对立就是非凸函数。凸函数的一个好处就是，对于优化得到的局部最优点，一定是一个全局最优点，因为凸函数只存在一个全局最优。而对于非凸函数，则存在非常多的局部最优点，还有非常多的鞍点。如下图所示:&lt;/p&gt;
&lt;div align=center&gt;
    &lt;img src=&#34;https://AIBluefisher.github.io/img/optimization/non_convex_function.jpg&#34;/&gt;
&lt;/div&gt;
&lt;p&gt;对于非凸优化问题，当优化算法收敛的时候，不利用其他信息，很难判断是否收敛到全局最优。因而非凸优化问题的求解要想尽可能的逼近全局最优，需要有较为可靠的初始值。很不幸的是，我们面临的大多数问题都是非凸优化问题。&lt;/p&gt;
&lt;h2 id=&#34;2-l_1-范数-vs-l_2-范数&#34;&gt;2. $l_1$-范数 VS $l_2$-范数&lt;/h2&gt;
&lt;p&gt;对于优化问题，我们通常想要最小化估计值 $f(x)$ 和目标值 $y$ 之间的残差(residual)&lt;/p&gt;
&lt;p&gt;$$
\min d(y, f(x))^p　\tag{3}
$$&lt;/p&gt;
&lt;p&gt;其中，$d(,)^p$ 表示误差度量的范数。对于向量来说，常见的有 $l_1$-范数、$l_2$-范数。
如果是 $l_1$-范数，残差是目标值和估计值之差的绝对值之和:&lt;/p&gt;
&lt;p&gt;$$
S = \sum_{i=1}^n |y_i - f(x_i)| \tag{4}
$$&lt;/p&gt;
&lt;p&gt;如果是 $l_2$-范数，残差是目标值和估计值之差的平方和:&lt;/p&gt;
&lt;p&gt;$$
S = \sum_{i=1}^n (y_i - f(x_i))^2 \tag{5}
$$&lt;/p&gt;
&lt;p&gt;那么 使用　$l_1$-范数做优化和 $l_2$-范数来做优化有什么区别呢？
我们知道，真实的观测数据通常存在外点 (outliers)。outlier的存在会导致优化时的最优点偏离真实的最优点。在外点存在的情况下，$l_1$-范数会比$l_2$-范数鲁棒。虽然这在理论上并没有严格的证明，不过从直观上来讲，由于 $l_2$-范数对误差进行了平方，因此相比 $l_1$-范数来说，外点会贡献更多的误差(如果 $e &amp;gt; 1$, $e^2 &amp;gt; e$)。而优化算法又需要最小化误差，因此会导致优化会更多地朝着外点的方向去调整。&lt;/p&gt;
&lt;p&gt;这两种范数度量之间的比较:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$l_1$-范数比 $l_2$-范数更鲁棒&lt;/li&gt;
&lt;li&gt;$l_2$-范数比 $l_1$-范数更稳定&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-最小二乘法&#34;&gt;3. 最小二乘法&lt;/h2&gt;
&lt;h3 id=&#34;31-最小二乘问题&#34;&gt;3.1 最小二乘问题&lt;/h3&gt;
&lt;p&gt;最小二乘问题的定义是&lt;/p&gt;
&lt;p&gt;$$
\min f(x) = \frac{1}{2} \sum_{i=1}^m r_i^2(x) = \frac{1}{2}r(x)^Tr(x), x \in \mathbb{R}^n, m \geq n \tag{6}
$$&lt;/p&gt;
&lt;p&gt;这里 $r(x) = [r_1(x), r_2(x), \cdots, r_m(x)]^T$ 称作剩余函数(残差）。若 $r_i(x)$ 均为线性函数，则问题为&lt;code&gt;线性最小二乘问题&lt;/code&gt;；若至少有一个 $r_i(x)$ 为非线性函数，则问题为&lt;code&gt;非线性最小二乘问题&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;下面我们来看最小二乘问题的目标函数 $f(x)$ 的一、二阶导数的形式。设 $J(x)$ 是 $r(x)$ 的 Jacobi 矩阵:&lt;/p&gt;
&lt;p&gt;$$
J(x) = [\nabla r_1(x), \cdots, \nabla r_m(x)]^T \in \mathbb{R}^{m \times n}
$$&lt;/p&gt;
&lt;p&gt;则 $f(x)$ 的梯度为&lt;/p&gt;
&lt;p&gt;$$
g(x) = \sum_{i=1}^m r_i(x) \nabla r_i(x) = J(x)^T r(x) \tag{7}
$$&lt;/p&gt;
&lt;p&gt;$f(x)$ 的 Hessian 矩阵为&lt;/p&gt;
&lt;p&gt;$$
G(x) = \sum_{i=1}^m \nabla r_i(x) \nabla r_i(x)^T + \sum_{i=1}^m r_i(x)\nabla^2 r_i(x) = J(x)^T J(x) + S(x) \tag{8}
$$&lt;/p&gt;
&lt;p&gt;其中，$S(x) = \sum_{i=1}^m r_i(x) \nabla^2 r_i(x)$。&lt;/p&gt;
&lt;h3 id=&#34;32-最小二乘的来源&#34;&gt;3.2 最小二乘的来源&lt;/h3&gt;
&lt;p&gt;最小二乘问题大量产生于数据拟合问题: 给定一组实验数据 $(x_i, y_i)$ 和函数模型 $f(x)$，要确定 $x$，使得 $f(x)$ 在残差的平方和意义下尽可能地拟合给定的数据。即&lt;/p&gt;
&lt;p&gt;$$
\arg\min_x \sum_{i=1}^n ||y_i - f(x_i)||_2^2 \tag{9}
$$&lt;/p&gt;
&lt;p&gt;最小二乘问题和极大似然估计之间存在联系。我们通常假定误差遵循高斯(正态)分布。具体来讲，我们假定目标值和观测值之间都具有零均值和标准差为 $\sigma$ 的高斯噪声。若真值为 $y_i$，估计值为 $f(x_i)$，那么每个估计值的概率密度函数是&lt;/p&gt;
&lt;p&gt;$$
Pr(x_i) = \frac{1}{2\pi \sigma^2} e^{-\frac{(y_i - f(x_i))^2}{2\sigma^2}} \tag{10}
$$&lt;/p&gt;
&lt;p&gt;假设误差独立同分布，那么联合概率密度函数为&lt;/p&gt;
&lt;p&gt;$$
Pr(x) = \prod_i Pr(x_i) = \prod_i \frac{1}{2\pi \sigma^2} e^{-\frac{(y_i - f(x_i))^2}{2\sigma^2}} \tag{11}
$$&lt;/p&gt;
&lt;p&gt;对应的对数似然函数为:&lt;/p&gt;
&lt;p&gt;$$
log Pr(x) = -\frac{1}{2\pi \sigma^2} \sum_i (y_i - f(x_i))^2 + c \tag{12}
$$&lt;/p&gt;
&lt;p&gt;最大似然估计最大化这个对数似然函数，也即最小化&lt;/p&gt;
&lt;p&gt;$$
\sum_i (y_i - f(x_i))^2 \Leftrightarrow \sum_i ||y_i - f(x_i)||_2^2 \tag{13}
$$&lt;/p&gt;
&lt;h3 id=&#34;33-鲁棒最小二乘和迭代重加权irls-问题&#34;&gt;3.3 鲁棒最小二乘和迭代重加权(IRLS) 问题&lt;/h3&gt;
&lt;p&gt;常规的最小二乘对其中噪声符合高斯分布的观测值来说是一个合适的选择，然而在存在外点的时，需要更鲁棒的最小二乘。这种情况下，最好用M-估计(M-estimator)，它对残差施加一个鲁棒惩罚函数 $\rho (r) $ (也称为 &lt;code&gt;loss function&lt;/code&gt;)
$$
E_{RLS(\triangle \boldsymbol{x})} = \sum_{i} \rho(||\boldsymbol{r}_i||) \tag{14}
$$
来代替它们的平方&lt;/p&gt;
&lt;p&gt;$$
E_{LS(\triangle \boldsymbol{x})} = \sum_{i} ||\boldsymbol{r}_i||_2^2 \tag{15}
$$&lt;/p&gt;
&lt;p&gt;其中 $\boldsymbol{r}_i = y_i - f(x_i)$ 。公式(14)对$\boldsymbol{x}$求偏导，则有&lt;/p&gt;
&lt;p&gt;$$
\sum_{i} \frac{\partial \rho (||\boldsymbol{r}_i||)}{\partial ||\boldsymbol{r_i}||} \cdot\frac{\partial ||\boldsymbol{r}_i||}{\partial \boldsymbol{x}}\&lt;br&gt;
= \sum_i \frac{\partial \rho (||\boldsymbol{r}_i||)}{\partial ||\boldsymbol{r_i}|| \cdot ||\boldsymbol{r}_i||} \cdot \boldsymbol{r}_i^T \frac{\partial ||\boldsymbol{r}_i||}{\partial \boldsymbol{x}}\&lt;br&gt;
= \sum_i \frac{\Psi (||\boldsymbol{r}_i||)}{||\boldsymbol{r}_i||} \cdot \boldsymbol{r}_i^T \frac{\partial ||\boldsymbol{r}_i||}{\partial \boldsymbol{x}} \ \ \ \ \ \ \ \&lt;br&gt;
= \sum_i w(||\boldsymbol{r}_i||) \cdot \boldsymbol{r}_i^T \frac{\partial ||\boldsymbol{r}_i||}{\partial \boldsymbol{x}} = 0 \ \ \tag{16}
$$&lt;/p&gt;
&lt;p&gt;其中 $\Psi (||\boldsymbol{r}_i||) = \frac{\partial \rho (||\boldsymbol{r}_i||)}{\partial ||\boldsymbol{r_i}||}$，称为&lt;code&gt;影响函数 (influence function)&lt;/code&gt;，$w(r) = \frac{\Psi(r)}{r}$ 称为&lt;code&gt;加权函数(weight function)&lt;/code&gt;。可以看出用公式(12)求解 (10)的极小值等于最小化&lt;code&gt;迭代重加权最小二乘 (Iteratively Reweighted Least Squares, IRLS)问题&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;$$
E_{IRLS} = \sum_i w(||\boldsymbol{r}_i||)||\boldsymbol{r}_i||^2 \tag{17}
$$&lt;/p&gt;
&lt;p&gt;其中 $w(||\boldsymbol{r}_i||)$ 起着局部加权作用。IRLS 算法在计算影响函数 $w(||\boldsymbol{r}_i||)$ 和求解得到的加权最小二乘问题(固定的 $w$ 值) 之间交替。M-estimator 一定能够减少外点的影响，但是在一些情况中，从太多外点起步的话会使得 IRLS(或者其他梯度下降算法) 不能收敛到全局最优。&lt;/p&gt;
&lt;h2 id=&#34;4-优化问题在三维视觉中的应用&#34;&gt;4. 优化问题在三维视觉中的应用&lt;/h2&gt;
&lt;h3 id=&#34;41-rotation-averaging&#34;&gt;4.1 Rotation Averaging&lt;/h3&gt;
&lt;h4 id=&#34;411-相对运动和全局姿态的约束关系&#34;&gt;4.1.1 相对运动和全局姿态的约束关系&lt;/h4&gt;
&lt;p&gt;Rotation Averaging 是 Structure from Motion (SfM) 的一个子问题，现在在SLAM方面也有应用。无论是SfM还是SLAM，都需要估计摄像机的姿态 (pose)，摄像机的姿态由旋转 (rotation，或是朝向 orientation) 和平移 (translation，也可以说是摄像机位置)构成。&lt;/p&gt;
&lt;p&gt;问题描述为: 给定 $N$ 张图片，全局运动可以用 $N-1$ 个运动模型描述。两个相机之间的相对运动关系可以通过对极几何估计&lt;code&gt;本质矩阵(Essential Matrix)&lt;/code&gt;，再进行矩阵分解(对本质矩阵的奇异值分解)得到。我们可以通过相对相机运动来估计全局相机运动模型。如果每对图片之间都有足够的重叠，那么我们可以得到 $\frac{N(N-1)}{2}$ 对约束(虽然实际上不可能存在这么多对，但一般也存在远多于 $N$ 的约束)。&lt;/p&gt;
&lt;p&gt;为了求解 RA 问题，首先来推几个公式。假设已知两个相机在全局坐标系下的运动，那么这两个相机之间的相对运动是怎样的关系呢？&lt;/p&gt;
&lt;p&gt;已知点 $P$ 在世界坐标系中的坐标，记为 $P_0$。对于两个不同的相机 $i$ 和 $j$，对应于全局坐标系中的旋转和平移分别为 $R_i, t_i, R_j, t_j$ 。将点 $P_0$ 分别投影到相机 $i$ 和 $j$ 的坐标系，那么有&lt;/p&gt;
&lt;p&gt;$$
P_i = R_iP_0 + t_j\ (18.a) \
P_j = R_jP_0 + t_j\ (18.b)
$$&lt;/p&gt;
&lt;p&gt;由公式(18.a)我们可以得到&lt;/p&gt;
&lt;p&gt;$$P_0 = R_i^{-1}(P_i - t_i)\ \tag{18} $$&lt;/p&gt;
&lt;p&gt;将公式(19)代入(18.b)中，有
$$
P_j = R_j(R_i^{-1}(P_i - t_i)) + t_j\&lt;br&gt;
\ = R_jR_i^{-1}P_i + (t_j - R_jR_i^{-1}t_i)\ \tag{20}
$$
由公式(19)我们可以得到相机 $i$ 到相机 $j$ 的相对运动关系:
$$
R_{ij} = R_jR_i^{-1} = R_jR_i^{T}\ (21.a)\&lt;br&gt;
t_{ij} = t_j - R_jR_i^{-1}t_i = t_j - R_{ij}t_i\ (21.b)
$$
这里需要注意的是 ***$R_{ij}$ 和 $t_{ij}$是相机 $i$ 相对于 $j$ 的运动*** 。&lt;/p&gt;
&lt;h4 id=&#34;412-ra-问题的优化求解&#34;&gt;4.1.2 RA 问题的优化求解&lt;/h4&gt;
&lt;p&gt;给定参考系和一系列相对旋转 ${R_{ij}}$，我们希望求解 $R_{global} = {R_1, \cdots, R_N}$。我们希望最小化代价函数:
$$
\arg\min_{R_i} \sum_{(i,j)\in \mathcal{E}} d^2(R_{ij}, R_jR_i^{-1}) \tag{22}
$$
现在我们考虑使用李代数来进行优化, $R_{ij} = exp([\boldsymbol{w_{ij}}]_{\times}), R_i = exp([\boldsymbol{w_{i}}]_{\times})$，其中 $\boldsymbol{w_{ij}}$ 和 $\boldsymbol{w_{i}}$ 分别为 $R_{ij}$ 和 $R_i$ 对应的李代数。&lt;/p&gt;
&lt;p&gt;假设只考虑其中一对关系 $R_{ij} = R_jR_i^{-1}$。由 BCH 公式： $BCH(x, y) = x + y + \frac{1}{2}[x, y] + \frac{1}{12}[x - y, [x, y]] + o(|(x, y)|^4)$，若只采用BCH公式的一阶估计 $BCH(x, y) \approx x + y$，则&lt;/p&gt;
&lt;p&gt;$$
\boldsymbol{w_{ij}} = BCH(\boldsymbol{w_{j}}, -\boldsymbol{w_{i}}) = \boldsymbol{w_{j}} - \boldsymbol{w_{i}}
$$&lt;/p&gt;
&lt;p&gt;令全局坐标系下旋转的李代数表示为 $\boldsymbol{\omega}_{global} = [\boldsymbol{\omega}_1, \cdots, \boldsymbol{\omega}_N]^T$，那么我们有&lt;/p&gt;
&lt;p&gt;$$
\boldsymbol{w_{ij}} = \boldsymbol{w_{j}} - \boldsymbol{w_{i}} =
\left[
\begin{array}{cccc}
\cdots &amp;amp; -I &amp;amp; \cdots &amp;amp; I &amp;amp; \cdots
\end{array}
\right]
\boldsymbol{w_{global}}
= A_{ij}\boldsymbol{w_{global}} \tag{23}
$$&lt;/p&gt;
&lt;p&gt;在 $A_{ij}$ 中，$I$ 和 $_I$ 为在 $i$ 和 $j$ 处的 $3\times 3$ 的块矩阵。把所有的相对运动关系拼合起来，我们有
$$
A\boldsymbol{w_{global}} = \boldsymbol{w_{rel}} \tag{24}
$$&lt;/p&gt;
&lt;p&gt;现在，我们要做的就是如何求解这个非齐次线性方程组了。&lt;/p&gt;
&lt;h5 id=&#34;1-l_1-rotation-averaging&#34;&gt;(1) $l_1$ Rotation Averaging&lt;/h5&gt;
&lt;p&gt;考虑非齐次线性方程组 $A\boldsymbol{x} = \boldsymbol{b}$，其中 $\boldsymbol{x} \in \mathbb{R}^n, \boldsymbol{b} \in \mathbb{R}^m$，并且 $m &amp;gt; n$。这个方程的求解难度由于噪声和外点的存在发生了改变，比如 $\boldsymbol{b} = A\boldsymbol{x} + \boldsymbol{e} $。在压缩感知方向的一些研究表明，在外点存在的情况下，$\boldsymbol{x}$ 可以通过以下公式高效精确地求解:&lt;/p&gt;
&lt;p&gt;$$
\arg\min_x ||A\boldsymbol{x} - \boldsymbol{b}||_{l_1} \tag{25}
$$&lt;/p&gt;
&lt;h5 id=&#34;2-irls-rotation-averaging&#34;&gt;(2) IRLS Rotation Averaging&lt;/h5&gt;
&lt;p&gt;$l_1$优化得到的结果还能进一步提升。现在考虑使用 IRLS 算法来求解 Rotation Averaging 问题，令残差为 $\boldsymbol{e} = A\boldsymbol{x} - \boldsymbol{b}$，我们希望最小化鲁棒代价函数&lt;/p&gt;
&lt;p&gt;$$
E_{RLS} = \sum_i \rho(||\boldsymbol{e}_i||) \tag{26}
$$&lt;/p&gt;
&lt;p&gt;这里，loss function 选则 Huber-like loss function: $\rho(x) = \frac{x^2}{x^2 + \sigma^2}$。因此，&lt;/p&gt;
&lt;p&gt;$$
min\ E_{RLS} = min\ \sum_i \rho(||\boldsymbol{e}_i||) = min\ \sum_i \frac{\boldsymbol{e}_i^2}{\boldsymbol{e}_i^2 + \sigma^2} \tag{27}
$$&lt;/p&gt;
&lt;p&gt;公式(27)对 $\boldsymbol{x}$ 求偏导，有&lt;/p&gt;
&lt;p&gt;$$
\frac{\partial E_{RLS}}{\partial \boldsymbol{x}} = \frac{\partial E_{RLS}}{\partial \boldsymbol{e}} \cdot \frac{\partial \boldsymbol{e}}{\partial \boldsymbol{x}} \qquad \qquad \qquad \qquad \ \&lt;br&gt;
= \frac{2||\boldsymbol{e}_i||(||\boldsymbol{e}_i||^2 + \sigma^2) - 2||\boldsymbol{e}_i||\cdot ||\boldsymbol{e}_i||^2}{(||\boldsymbol{e}_i||^2 + \sigma^2)^2} \cdot A^T\&lt;br&gt;
= \frac{2||\boldsymbol{e}_i||\sigma^2}{(||\boldsymbol{e}_i||^2 + \sigma^2)^2} \cdot A^T \qquad \qquad \qquad \qquad \quad \&lt;br&gt;
= \frac{2(A\boldsymbol{x}-b)\sigma^2 A^T}{(||\boldsymbol{e}_i||^2 + \sigma^2)^2} \qquad \qquad \qquad \qquad \qquad \&lt;br&gt;
= 2 \cdot \frac{A^T \sigma^2A\boldsymbol{x}- A^T\sigma^2b}{(||\boldsymbol{e}_i||^2 + \sigma^2)^2} = 0 \qquad \qquad \qquad\  \tag{28}
$$&lt;/p&gt;
&lt;p&gt;因此，有&lt;/p&gt;
&lt;p&gt;$$
A^T\Phi(\boldsymbol{e})A\boldsymbol{x} - A^T\Phi(\boldsymbol{e}) \boldsymbol{b} = 0\ \Rightarrow \&lt;br&gt;
A^T\Phi(\boldsymbol{e})A\boldsymbol{x} = A^T\Phi(\boldsymbol{e}) \boldsymbol{b} \tag{29}
$$&lt;/p&gt;
&lt;p&gt;其中，$\Phi(\boldsymbol{e})$ 是对角阵并且 $\Phi(i, i) = \frac{\sigma^2}{(\boldsymbol{e}_i^2 + \sigma^2)^2}$ 。&lt;/p&gt;
&lt;p&gt;由公式 (17), RLS 问题可以转变为求解 IRLS 问题： $min\ (A\boldsymbol{x} - \boldsymbol{b})^T\Phi(A\boldsymbol{x} - \boldsymbol{b})$，由公式 (29) 知，其最优点为&lt;/p&gt;
&lt;p&gt;$$\boldsymbol{x} = (A^T \Phi A)^{-1} A^T \Phi \boldsymbol{b} \tag{30}$$&lt;/p&gt;
&lt;p&gt;在 IRLS 中，我们先固定$\boldsymbol{x}$，然后计算 $\Phi$；接着固定 $\Phi$ (由公式 (30) 计算得到)。通过这样一个交替的方式直到收敛。&lt;/p&gt;
&lt;p&gt;如果没有一个好的初值的话，&lt;code&gt;IRLS&lt;/code&gt; 算法很有可能不能收敛到全局最优，而由于 &lt;code&gt;L1RA&lt;/code&gt; 算法对于 $R_{gobal}$ 来说足够提供一个好的初值，因此 &lt;code&gt;L1RA&lt;/code&gt; 算法的输出可以作为 &lt;code&gt;IRLS&lt;/code&gt; 算法的输入。到这里，我们可以直到，整个使用 $l_1$-范数求解 Rotion Averaging 问题的算法(L1-IRLS)可以分为两步: (1) &lt;code&gt;L1RA&lt;/code&gt;算法求解 $R_{global}$ 的初值；（2）$R_{global}$ 的初值作为 &lt;code&gt;IRLS&lt;/code&gt; 的输入，使用算法2求解得到最终的 $R_{global}$ 。&lt;/p&gt;
&lt;h3 id=&#34;42-光束平差法-bundle-adjustment&#34;&gt;4.2 光束平差法 (Bundle Adjustment)&lt;/h3&gt;
&lt;h4 id=&#34;421-相机投影模型&#34;&gt;4.2.1 相机投影模型&lt;/h4&gt;
&lt;p&gt;为了理解 Bundle Adjustment，首先需要了解空间中的三维点重投影回图像平面的过程。如下图所示，$p$ 是空间中的三维点，$o-xyz$ 是相机坐标系，$o‘-x’y‘$ 是成像平面，成像平面内的蓝色区域是像素平面(图像平面)，$f$ 是焦距。对于世界坐标系中的三维点，首先要通过相机在世界坐标系中的旋转和平移变换到相机坐标系 ($x = RX + t$)，进行归一化后，对归一化后的点进行去畸变，最后通过内参矩阵 $K$ 投影到图像平面。这一过程通过函数 $\pi(C_j, X_i)$ 描述。&lt;/p&gt;
&lt;div align=center&gt;
    &lt;img src=&#34;https://AIBluefisher.github.io/img/optimization/pinhole_camera_model1.jpg&#34;/&gt;
&lt;/div&gt;
&lt;h4 id=&#34;422-ba-求解&#34;&gt;4.2.2 BA 求解&lt;/h4&gt;
&lt;p&gt;BA 最小化重投影误差&lt;/p&gt;
&lt;p&gt;$$
min\ \sum_{i=1}^{n} \sum_{j=1}^m ||u_{ij} - \pi(C_j, X_i)||_2^2 \tag{31}
$$&lt;/p&gt;
&lt;p&gt;其中 $n$ 为三维点的个数，$m$ 为相机个数。&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
    &lt;img src=&#34;https://AIBluefisher.github.io/img/optimization/bundle_adjustment1.jpg&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;令残差 $r_{ij} = u_{ij} - \pi(C_j, X_i)$，公式 (31) 可重写为&lt;/p&gt;
&lt;p&gt;$$
\min\ r^Tr \tag{32}
$$&lt;/p&gt;
&lt;p&gt;对 $r$ 进行泰勒展开&lt;/p&gt;
&lt;p&gt;$$
r(x + \delta x) = r(x) + g^T \delta x + \frac{1}{2}\delta x^T H \delta x + o(||\delta x||^2)\tag{33}
$$&lt;/p&gt;
&lt;p&gt;(33) 右边对 $\delta x$ 求导，并令其等于０，可以得到&lt;/p&gt;
&lt;p&gt;$$
H\delta x = -g \tag{34}
$$&lt;/p&gt;
&lt;p&gt;公式 (34) 其实就是&lt;code&gt;牛顿方程 (Newton Equation)&lt;/code&gt;。对于最小二乘问题来说， $H = J^T J + S, g = J^Tr$，其中 $S = \sum_{i=1}^n \sum_{j=1}^m r_{ij}\nabla^2 r_{ij}$。如果残差足够小，那么我们可以忽略 $S$。这个时候我们就可以得到高斯牛顿  (Gauss-Newton) 方程&lt;/p&gt;
&lt;p&gt;$$
J^TJ \delta x = -J^Tr \tag{35}
$$&lt;/p&gt;
&lt;p&gt;由 (35) 可知，当 $J$ 满秩，$g$ 不为0 的时候，$\delta x$ 一定是下降方向，因为 $(\delta x)^T g = (\delta x)^T J^T r = -(\delta x)^T J^T J \delta x = -||J \delta x||^2 &amp;lt; 0$。但是当 $J^TJ$ 奇异的时候，高斯牛顿法在数值上会变得不稳定。这个时候，我们可以用 Levenberg-Marquardt 方法来代替&lt;/p&gt;
&lt;p&gt;$$
(J^TJ + \lambda I)\delta x = -J^T r \tag{36}
$$&lt;/p&gt;
&lt;p&gt;对于 Bundle Adjustment 问题，似乎我们只需要用线性代数的知识，就能够很容易地求解 (35) 和 (36) 了。但事实上真的是这样吗？&lt;/p&gt;
&lt;p&gt;在三维重建中，我们可能需要优化非常多的相机和三维点，SfM 里优化几千个相机以及几百万甚至上千万个三维点的情形不在少数。这种情况下，Jacobian 矩阵的存储就是一大问题，除此之外，解这么大的一个方程组也会变得非常耗时。有没有什么方法能够让求解变得更快呢？我们先来分析分析Jocobian矩阵的结构。&lt;/p&gt;
&lt;p&gt;令 $\hat{u}_{ij} = \pi(C_j, X_i)$，其中需要优化的变量 $x$ 由相机参数 $C_j$ 和 三维点 $X_i$ 组成，因此我们把 $x$ 分成相机参数块 $c$ 和三维结构参数块 $p$&lt;/p&gt;
&lt;p&gt;$$
x = [c\ p] \tag{37}
$$&lt;/p&gt;
&lt;p&gt;由于&lt;/p&gt;
&lt;p&gt;$$
J_{ij} = \frac{\partial r_{ij}}{\partial x_k} = \frac{\partial \hat{u}_{ij}}{\partial x_k}
$$&lt;/p&gt;
&lt;p&gt;我们很容易发现:&lt;/p&gt;
&lt;p&gt;$$
\frac{\partial \hat{u}&lt;em&gt;{ij}}{\partial c_k} = 0, \forall j \neq k,
\frac{\partial \hat{u}&lt;/em&gt;{ij}}{\partial p_k} = 0, \forall i \neq k
$$&lt;/p&gt;
&lt;p&gt;为了方便起见，现在我们考虑上图只有3个相机和4个三维点的情况，其中每个相机都能观测到这4个三维点。令 $A_{ij} = \frac{\partial \hat{u}_{ij}}{\partial c_j}, B_{ij} = \frac{\partial \hat{u}_{ij}}{\partial p_j}$，我们可以求得 Jacobian 矩阵:&lt;/p&gt;
&lt;p&gt;$$
J =
\left[
\begin{array}{ccccccc}
A_{11} &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{11} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\&lt;br&gt;
0 &amp;amp; A_{12} &amp;amp; 0 &amp;amp; B_{12} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\&lt;br&gt;
0 &amp;amp; 0 &amp;amp; A_{13} &amp;amp; B_{13} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\&lt;br&gt;
A_{21} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{21} &amp;amp; 0 &amp;amp; 0\&lt;br&gt;
0 &amp;amp; A_{22} &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{22} &amp;amp; 0 &amp;amp; 0\&lt;br&gt;
0 &amp;amp; 0 &amp;amp; A_{23} &amp;amp; 0 &amp;amp; B_{23} &amp;amp; 0 &amp;amp; 0\&lt;br&gt;
A_{31} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{31} &amp;amp; 0\&lt;br&gt;
0 &amp;amp; A_{32} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{32} &amp;amp; 0\&lt;br&gt;
0 &amp;amp; 0 &amp;amp; A_{33} &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{33} &amp;amp; 0\&lt;br&gt;
A_{41} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{41}\&lt;br&gt;
0 &amp;amp; A_{42} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{42}\&lt;br&gt;
0 &amp;amp; 0 &amp;amp; A_{43} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; B_{43}
\end{array}
\right] \tag{38}
$$&lt;/p&gt;
&lt;p&gt;现在我们可以发现，BA 中的 Jacobian 是一个稀疏的矩阵，它包含了大量的零元素。那么，对于高斯牛顿方程和LM方法里的 $J^TJ$，我们也不难发现它的稀疏性。令&lt;/p&gt;
&lt;p&gt;$$
U_j = \sum_{i=1}^4 A_{ij}^T A_{ij}, V_i = \sum_{j=1} B_{ij}^T B_{ij}, W_{ij} = A_{ij}^T B_{ij} \tag{39}
$$&lt;/p&gt;
&lt;p&gt;$$
J^T J =
\left[
\begin{array}{ccccccc}
U_1 &amp;amp; 0 &amp;amp; 0 &amp;amp; W_{11} &amp;amp; W_{21} &amp;amp; W_{31} &amp;amp; W_{41}\&lt;br&gt;
0 &amp;amp; U_2 &amp;amp; 0 &amp;amp; W_{12} &amp;amp; W_{22} &amp;amp; W_{32} &amp;amp; W_{42}\&lt;br&gt;
0 &amp;amp; 0 &amp;amp; U_3 &amp;amp; W_{13} &amp;amp; W_{23} &amp;amp; W_{33} &amp;amp; W_{43}\&lt;br&gt;
W_{11}^T &amp;amp; W_{12}^T &amp;amp; W_{13}^T &amp;amp; V_1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\&lt;br&gt;
W_{21}^T &amp;amp; W_{22}^T &amp;amp; W_{23}^T &amp;amp; 0 &amp;amp; V_2 &amp;amp; 0 &amp;amp; 0\&lt;br&gt;
W_{31}^T &amp;amp; W_{32}^T &amp;amp; W_{33}^T &amp;amp; 0 &amp;amp; 0 &amp;amp; V_3 &amp;amp; 0\&lt;br&gt;
W_{41}^T &amp;amp; W_{42}^T &amp;amp; W_{43}^T &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; V_4
\end{array}
\right]
\tag{40}
$$&lt;/p&gt;
&lt;p&gt;现在，我们可以看到 Ba 中 Hessian 的近似 $J^TJ$ 也是一个稀疏的矩阵。对于更大规模的情况，Hessian的稀疏性如下图所示(注意这张图里的相机和三维点的顺序不一样):&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
    &lt;img src = &#34;/img/optimization/hessian.png&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;对于 (36) 的右边，有&lt;/p&gt;
&lt;p&gt;$$
J^T r =
\left(
\begin{array}{c}
\sum_{i=1}^4(A_{i1}^T r_{i1})\&lt;br&gt;
\sum_{i=1}^4(A_{i2}^T r_{i2})\
\sum_{i=1}^4(A_{i3}^T r_{i3})\
\sum_{j=1}^3 (B_{ij}^T r_{ij})\
\sum_{j=1}^3 (B_{ij}^T r_{2j})\
\sum_{j=1}^3 (B_{ij}^T r_{3j})\
\sum_{j=1}^3 (B_{ij}^T r_{4j})
\end{array}
\right)
\tag{41}
$$&lt;/p&gt;
&lt;p&gt;令&lt;/p&gt;
&lt;p&gt;$$
r_{c_j} = \sum_{i=1}^4(A_{ij}^T r_{ij})^T, r_{p_i} = \sum_{j=1}^3(B_{ij}^T r_{ij})^T,
r_{ij} = u_{ij} - \hat{u_{ij}}
\tag{42}
$$&lt;/p&gt;
&lt;p&gt;并且&lt;/p&gt;
&lt;p&gt;$$
U = diag{U_1, U_2, U_3},
V = diag{V_1, V_2, V_3, V_4},
\tag{43}
$$&lt;/p&gt;
&lt;p&gt;$$
W = \left[
\begin{array}{cccc}
W_{11} &amp;amp; W_{21} &amp;amp; W_{31} &amp;amp; W_{41} \&lt;br&gt;
W_{12} &amp;amp; W_{22} &amp;amp; W_{32} &amp;amp; W_{42} \&lt;br&gt;
W_{13} &amp;amp; W_{23} &amp;amp; W_{33} &amp;amp; W_{43}
\end{array}
\right]
\tag{44}
$$&lt;/p&gt;
&lt;p&gt;我们把 (42)、(43)、(44) 代入 (35) 中，并且令 $\delta x = (\delta c\ \delta p)^T$，可以得到&lt;/p&gt;
&lt;p&gt;$$
\left[
\begin{array}{cc}
U &amp;amp; W  \&lt;br&gt;
W^T &amp;amp; V
\end{array}
\right]
\left[
\begin{array}{c}
\delta c \&lt;br&gt;
\delta p
\end{array}
\right] =
\left[
\begin{array}{c}
r_c \&lt;br&gt;
r_p
\end{array}
\right]
\tag{45}
$$&lt;/p&gt;
&lt;p&gt;现在，直接求解(45)在时间和空间上肯定是不可行的。注意到，(45) 中 $U, \delta c$ 是和相机相关的参数，$V,\delta p$ 是和三维点相关的参数，实际中的相机数远小于三维点的数量。因此，我们可以考虑先消去和三维点相关的参数，求得相机之后再代回求解三维点。现在，我们对 (45) 的左右两边同乘 $[I -WV^{-1}]^T$，可以得到&lt;/p&gt;
&lt;p&gt;$$
\left[
\begin{array}{cc}
U-WV^{-1}W^T &amp;amp; 0
\end{array}
\right]
\left[
\begin{array}{c}
\delta c \&lt;br&gt;
\delta p
\end{array}
\right] =
\left[
\begin{array}{cc}
I &amp;amp; -WV^{-1}  \&lt;br&gt;
\end{array}
\right]
\left[
\begin{array}{c}
r_c \&lt;br&gt;
r_p
\end{array}
\right]
\tag{46}
$$
进一步我们可以得到
$$
(U - WV^{-1}W^T)\delta c = r_c - WV^{-1}r_p \tag{47}
$$&lt;/p&gt;
&lt;p&gt;BA中，(47) 称作&lt;code&gt;Reduced Camera System&lt;/code&gt;，$S = U - WV^{-1}W^T$ 称作 $V$ 的 &lt;code&gt;Schur Complement&lt;/code&gt; 。可以证明，对称正定矩阵的 Schur Complement 是一个对称正定矩阵。因此，(47) 可以通过&lt;code&gt;乔里斯基分解 (Cholesky Decomposition)&lt;/code&gt; 进行求解。由 (46)，我们有&lt;/p&gt;
&lt;p&gt;$$
W^T\delta c + V\delta p = r_c \tag{48}
$$&lt;/p&gt;
&lt;p&gt;在求解得到相机之后，由 (48)，我们有&lt;/p&gt;
&lt;p&gt;$$
\delta p = V^{-1}(r_p - W^T\delta c) \tag{49}
$$&lt;/p&gt;
&lt;p&gt;到这里，BA 的求解基本上可以结束了。不过，为了加速BA，还有一些求解技巧，像 &lt;code&gt;Preconditioned Conjugate Gradient&lt;/code&gt;。对这些感兴趣的可以参考相关文献 [6,7,8]。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;p&gt;[1] Boyd. Convex Optimization.&lt;/p&gt;
&lt;p&gt;[2] Govindu V M . Combining two-view constraints for motion estimation[C]// Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on. IEEE, 2001.&lt;/p&gt;
&lt;p&gt;[3] Govindu V M . Lie-Algebraic Averaging for Globally Consistent Motion Estimation[C]// null. IEEE Computer Society, 2004.&lt;/p&gt;
&lt;p&gt;[4] Chatterjee A , Govindu V M . Efficient and Robust Large-Scale Rotation Averaging[C]// 2013 IEEE International Conference on Computer Vision (ICCV). IEEE Computer Society, 2013.&lt;/p&gt;
&lt;p&gt;[5] Chatterjee A, Govindu V. Robust Relative Rotation Averaging[J]. IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2017, PP(99):1-1.&lt;/p&gt;
&lt;p&gt;[6] Lourakis M I A, Argyros A A. SBA: a software package for generic sparse bundle adjustment[J]. Acm Trans.math.softw, 2009, 36(1):2.&lt;/p&gt;
&lt;p&gt;[7] Triggs B, Mclauchlan P F, Hartley R I, et al. Bundle Adjustment — A Modern Synthesis[C]// International Workshop on Vision Algorithms: Theory and Practice. Springer-Verlag, 1999:298-372.&lt;/p&gt;
&lt;p&gt;[8] Jeong Y, Nistér D, Steedly D, et al. Pushing the envelope of modern methods for bundle adjustment.[J]. IEEE Trans Pattern Anal Mach Intell, 2012, 34(8):1605-1617.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>三维重建中的旋转(Rotation)</title>
      <link>https://AIBluefisher.github.io/post/rotation/</link>
      <pubDate>Tue, 16 Apr 2019 22:23:14 +0800</pubDate>
      <guid>https://AIBluefisher.github.io/post/rotation/</guid>
      <description>&lt;p&gt;旋转在三维重建中是比较重要的，这里主要对旋转的性质及应用做一些总结。&lt;/p&gt;
&lt;h3 id=&#34;1-旋转矩阵&#34;&gt;1. 旋转矩阵&lt;/h3&gt;
&lt;p&gt;设某个&lt;u&gt;单位正交基&lt;/u&gt; $(e_1, e_2, e_3)$ 经过一次旋转变成了 $(e_1^{&#39;}, e_2^{&#39;}, e_3^{&#39;})$ 。那么，对于同一个向量 $\boldsymbol{a}$ (注意该向量并没有随着坐标系的旋转而发生运动)，它在两个坐标系下的坐标为 $(a_1, a_2, a_3)^T$ 和 $(a_1^{&#39;}, a_2^{&#39;}, a_3^{&#39;})^T$。&lt;/p&gt;
&lt;p&gt;由坐标的定义，有：
$$
\left[
\begin{array}{ccc}
e_1 &amp;amp; e_2 &amp;amp; e_3
\end{array}
\right]
\left[
\begin{array}{c}
a_1 \ a_2 \ a_3
\end{array}
\right]=
\left[
\begin{array}{ccc}
e_1^{&#39;} &amp;amp; e_2^{&#39;} &amp;amp; e_3^{&#39;}
\end{array}
\right]
\left[
\begin{array}{c}
a_1^{&#39;} \ a_2^{&#39;} \ a_3^{&#39;}
\end{array}
\right] \tag{1}
$$
为描述两个坐标之间的关系，(1)左右两边同时乘以$(e_1^T, e_2^T, e_3^T)^T$，则有
$$
\left[
\begin{array}{c}
a_1 \ a_2 \ a_3
\end{array}
\right]=
\left[
\begin{array}{ccc}
e_1^{T}e_1{&#39;} &amp;amp; e_1^Te_2^{&#39;} &amp;amp; e_1^Te_3^{&#39;} \&lt;br&gt;
e_2^{T}e_1^{&#39;} &amp;amp; e_2^Te_2^{&#39;} &amp;amp; e_1^Te_3^{&#39;} \&lt;br&gt;
e_3^{T}e_1^{&#39;} &amp;amp; e_3^Te_2^{&#39;} &amp;amp; e_3^Te_3^{&#39;}
\end{array}
\right]
\left[
\begin{array}{c}
a_1^{&#39;} \ a_2^{&#39;} \ a_3^{&#39;}
\end{array}
\right] = R\boldsymbol{a^{&#39;}} \tag{2}
$$
其中 $R$ 即为旋转矩阵。旋转矩阵的集合定义为:
$$
SO(n) = {R \in \mathbb{R}^{n\times n} | RR^T = I, det(R) = I } \tag{3}
$$
由于旋转矩阵是正交阵，它的逆(即转置)描述了一个相反的旋转，则有$\boldsymbol{a^{&#39;}} = R^{-1}\boldsymbol{a}=R^T\boldsymbol{a}$。显然，$R^T$刻画了一个相反的旋转。&lt;/p&gt;
&lt;h3 id=&#34;2-李群和李代数-lie-group-and-lie-algebra&#34;&gt;2. 李群和李代数 (Lie Group and Lie Algebra)&lt;/h3&gt;
&lt;p&gt;这里我们只描述旋转空间上的&lt;code&gt;李群&lt;/code&gt;和&lt;code&gt;李代数&lt;/code&gt;。
李群是指具有连续光滑性质的群。$SO(n)$在实数空间上是连续的。我们能够直观想象一个刚体能够连续地在空间中运动，所以他们都是李群。每个李群都有与之对应的李代数，李代数描述了李群的局部性质。旋转空间上的李群已经在公式(3)中做了描述。&lt;/p&gt;
&lt;h4 id=&#34;21-旋转空间上的李代数推导&#34;&gt;2.1 旋转空间上的李代数推导&lt;/h4&gt;
&lt;p&gt;设 $R$ 为某个相机的旋转，随时间连续变化，即 $R$ 为关于时间 $t$ 的函数 $R(t)$。由于 $R$ 为正交阵，则有
$$
R(t)R(t)^T = I \tag{4}
$$
等式两边对 $t$ 求导，则有 $\frac{\delta R(t)}{\delta t} R(t)^T + R(t)\frac{\delta R(t)^T}{\delta t} = 0$。整理可得，
$$
\frac{\delta R(t)}{\delta t} R(t)^T = -R(t)\frac{\delta R(t)^T}{\delta t} = -(\frac{\delta R(t)}{\delta t} R(t)^T)^T \tag{5}
$$
由(5)可以看出 $\frac{\delta R(t)}{\delta t} R(t)^T$ 是一个&lt;code&gt;反对称矩阵&lt;/code&gt; (反对称矩阵的定义: $A = -A^T$)。
而对于&lt;code&gt;反对称矩阵&lt;/code&gt;，我们总能找到一个三维向量 $\boldsymbol{w}$ 与之对应。一般地，$[\boldsymbol{w}]&lt;em&gt;{\times}$ 表示向量到反对称阵的变换。因此，我们有
$$
\frac{\delta R(t)}{\delta t} R^T = [\boldsymbol{w}]&lt;/em&gt;{\times} \tag{6}
$$
对公式(6), 左右两边同时右乘$R(t)$可得
$$
\frac{\delta R(t)}{\delta t} = [\boldsymbol{w}]&lt;em&gt;{\times} R(t) \tag{7}
$$
公式(7)是一个形如 $\frac{\mathrm{d}y}{\mathrm{d}x} = ay$ 的常微分方程，对方程两边同时去倒数，则有 $\frac{\mathrm{d}x}{\mathrm{d}y} = \frac{1}{ay}$。显然，$\mathrm{d}x = \frac{1}{y}\mathrm{d}y$ 的解为 $x = ln\ ay$，进一步可得 $y = e^{ax}$。将公式(7)代入，可得
$$
R(t) = e^{[\boldsymbol{w}]&lt;/em&gt;{\times}t} \tag{8}
$$&lt;/p&gt;
&lt;h4 id=&#34;22-李代数-mathfrakso3&#34;&gt;2.2 李代数 $\mathfrak{so}(3)$&lt;/h4&gt;
&lt;p&gt;李群 $SO(3)$ 对应的李代数是定义在 $R(3)$ 上的向量，记为 $\boldsymbol{w}$。每个 $\boldsymbol{w}$ 都可以生成一个反对称矩阵 $\Phi$ :
$$
\Phi = [\boldsymbol{w}]&lt;em&gt;{\times} =
\left[
\begin{array}{ccc}
0 &amp;amp; -w_3 &amp;amp; w_2\&lt;br&gt;
w_3 &amp;amp; 0 &amp;amp; -w_1\&lt;br&gt;
-w_2 &amp;amp; w_1 &amp;amp; 0
\end{array}
\right]
\in \mathbb{R}^{3\times 3}
$$
一般说，$\mathfrak{so}(3)$的元素是三维向量或者三维反对称矩阵，不加区别:
$$
\mathfrak{so}(3) = {\boldsymbol{w} \in R^3, \Phi = [\boldsymbol{w}]&lt;/em&gt;{\times} \in \mathbb{R}^{3\times 3}} \tag{9}
$$
至此，我们知道 $\mathfrak{so}(3)$ 是一个由三维向量组成的集合，每个向量对应到一个反对称矩阵，可以表达旋转矩阵的倒数。它与 $\mathfrak{so}(3)$ 的关系通过&lt;code&gt;指数映射 (exponential mapping)&lt;/code&gt;给定:
$$
R = exp([\boldsymbol{w}]_{\times}) \tag{10}
$$&lt;/p&gt;
&lt;h4 id=&#34;23-推导-mathfrakso3-上的指数映射&#34;&gt;2.3 推导 $\mathfrak{so}(3)$ 上的指数映射&lt;/h4&gt;
&lt;p&gt;由 公式 (10) 可知，它是一个矩阵的指数。在李群和李代数中，称为&lt;code&gt;指数映射 (exponential mapping)&lt;/code&gt;。
我们知道指数函数的&lt;code&gt;幂级数&lt;/code&gt;为
$$
exp(x) = \sum_{n=0}^{\infty} \frac{x^n}{n!}
$$
同样地，对于 $\mathfrak{so}(3)$ 中的任意元素 $[\boldsymbol{w}]_{\times}$，它的指数映射为
$$
exp([\boldsymbol{w}]_{\times}) = \sum_{n=0}^{\infty} \frac{([\boldsymbol{w}]_{\times})^n}{n!} \tag{11}
$$
令 $\boldsymbol{w} = \theta \boldsymbol{a}$，其中$\theta$ 为方向，$\boldsymbol{a}$ 为长度为1的方向向量。对于 $[\boldsymbol{a}]_{\times}$，有两个性质：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$[\boldsymbol{a}]&lt;em&gt;{\times}[\boldsymbol{a}]&lt;/em&gt;{\times} = \boldsymbol{a}\boldsymbol{a}^T - I$&lt;/li&gt;
&lt;li&gt;$[\boldsymbol{a}]&lt;em&gt;{\times}[\boldsymbol{a}]&lt;/em&gt;{\times}[\boldsymbol{a}]&lt;em&gt;{\times} = -[\boldsymbol{a}]&lt;/em&gt;{\times}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;利用这两个性质，指数映射可以写为:
$$
exp([\boldsymbol{w}]&lt;em&gt;{\times}) = exp(\theta [\boldsymbol{a}]&lt;/em&gt;{\times})
= \sum_{n=0}^{\infty} \frac{(\theta [\boldsymbol{a}]_{\times})^n}{n!}\&lt;br&gt;
= I + \theta [\boldsymbol{a}]_{\times} + \frac{1}{2!} \theta^2 [\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} + \frac{1}{3!}\theta^3[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} + \frac{1}{4}\theta^4([\boldsymbol{a}]_{\times})^4 + \cdots\&lt;br&gt;
= \boldsymbol{a}\boldsymbol{a}^T - [\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} + \frac{1}{2!}\theta^2[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} + \frac{1}{3!}\theta^3[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} + \frac{1}{4!}\theta^4([\boldsymbol{a}]_{\times})^4 + \cdots\&lt;br&gt;
= \boldsymbol{a}\boldsymbol{a}^T - [\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} + \theta[\boldsymbol{a}]_{\times} + \frac{1}{2!}\theta^2[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} - \frac{1}{2!}\theta^3[\boldsymbol{a}]_{\times} - \frac{1}{4!}\theta^4([\boldsymbol{a}]_{\times})^2 + \cdots\&lt;br&gt;
= \boldsymbol{a}\boldsymbol{a}^T + (\theta - \frac{1}{3!}\theta^3 + \frac{1}{5!}\theta^5 - \cdots)[\boldsymbol{a}]_{\times} - (1 - \frac{1}{2!}\theta^2 + \frac{1}{4!}\theta^4 - \cdots)[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times}\&lt;br&gt;
=[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} + I + [\boldsymbol{a}]_{\times}sin\theta - [\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} cos\theta\&lt;br&gt;
= (1 - cos\theta)[\boldsymbol{a}]_{\times}[\boldsymbol{a}]_{\times} + I + [\boldsymbol{a}]_{\times} sin\theta\&lt;br&gt;
= (1-cos\theta)(\boldsymbol{a}\boldsymbol{a}^T - I) + I + [\boldsymbol{a}]_{\times}sin\theta\&lt;br&gt;
= cos\theta\ I + (1 - cos\theta)\boldsymbol{a}\boldsymbol{a}^T + [\boldsymbol{a}]_{\times}sin\theta
\tag{12}
$$
公式 (12) 就是&lt;code&gt;罗德里格斯公式&lt;/code&gt;，&lt;u&gt;指数映射即罗德里格斯公式&lt;/u&gt;！&lt;/p&gt;
&lt;p&gt;同样，我们可以定义&lt;code&gt;对数映射&lt;/code&gt;，把 $SO(3)$ 中的元素对应到 $\mathfrak{so}(3)$ 中 :
$$
\boldsymbol{[w]}&lt;em&gt;{\times} = ln(R)^{V} = (\sum&lt;/em&gt;{n=0}^{\infty} \frac{(-1)^n}{n+1} (R - I)^{n+1} )^{V} \tag{13}
$$
不过，一般不会按照泰勒展开计算对数映射，而是通过旋转矩阵恢复李代数：
令转轴为 $\boldsymbol{n}$，转角为 $\theta$，
(1) 计算转角 $\theta$。对于转角 $\theta$，由罗德里格斯公式，有
$$
tr(R) = cos\theta\ tr(I) + (1-cos\theta)tr(\boldsymbol{n}\boldsymbol{n}^T) + sin\theta\ tr([\boldsymbol{n}]_{\times})\&lt;br&gt;
= 3cos\theta + (1-cos\theta) = 1 + 2cos\theta
$$
，因此，$\theta = arc\ cos\frac{tr(R) - 1}{2}$。
(2) 计算转轴 $\boldsymbol{n}$，由于旋转轴上的向量在旋转后不发生改变，有 $R\boldsymbol{n} = \boldsymbol{n}$。因此，转轴 $\boldsymbol{n}$ 是矩阵 $R$ 特征值为1对应的特征向量。求解次方程，再归一化，就得到了转轴。最后，李代数可以写为 $\boldsymbol{w} = \theta\boldsymbol{n}$。&lt;/p&gt;
&lt;h3 id=&#34;3-四元数-quanternion&#34;&gt;3. 四元数 (Quanternion)&lt;/h3&gt;
&lt;p&gt;四元数是Hamilton找到的一种扩展的复数，拥有一个实部和三个虚部，可表示为 :
$$
\boldsymbol{q} = (c, \boldsymbol{v}) = (q_0, q_1, q_2, q_3) = q_0 + q_1\boldsymbol{i} + q_2\boldsymbol{j} + q_3\boldsymbol{k} \tag{14}
$$
这三个虚部满足以下关系:
$$
i^2 = j^2 = k^2 = -1\&lt;br&gt;
ij = k,\ ji = -k,\&lt;br&gt;
jk = i,\ kj = -i,\&lt;br&gt;
ki = j,\ ik = -j.
$$&lt;/p&gt;
&lt;h4 id=&#34;31-四元数的运算&#34;&gt;3.1 四元数的运算&lt;/h4&gt;
&lt;p&gt;设 $\boldsymbol{q} = (c_1, \boldsymbol{v}_1), q_2 = (c_2, \boldsymbol{v}_2)$，则
$$
\boldsymbol{q}_1 \pm \boldsymbol{q}_2 = (c_1 \pm c_2,\ \boldsymbol{v}_1 \pm \boldsymbol{v}_2)\&lt;br&gt;
\boldsymbol{q}_1 \cdot \boldsymbol{q}_2 = (c_1c_2 - \boldsymbol{v}_1^T\boldsymbol{v}_2,\ c_1\boldsymbol{v}_2 + c_2\boldsymbol{v}_1 + \boldsymbol{v}_1 \times \boldsymbol{v}_2)\&lt;br&gt;
||\boldsymbol{q}|| = \sqrt{q_0^2 + q_1^2 + q_2^2 + q_3^2},\
\boldsymbol{q}^{-1} = \frac{1}{||q||^2} (c,\ -\boldsymbol{v})\&lt;br&gt;
||\boldsymbol{q}_1 \cdot \boldsymbol{q}_2|| = ||\boldsymbol{q_1}|| \cdot ||\boldsymbol{q_2}||
$$&lt;/p&gt;
&lt;h4 id=&#34;32-四元数表示旋转&#34;&gt;3.2 四元数表示旋转&lt;/h4&gt;
&lt;p&gt;假设旋转绕单位向量 $\boldsymbol{n} = (n_x, x_y, n_z)^T$ 进行了角度为 $\theta$ 的旋转，则该旋转的四元数定义为:
$$
\boldsymbol{q} = (cos\frac{\theta}{2},\ n_xsin\frac{\theta}{2},\ n_ysin\frac{\theta}{2},\ n_zsin\frac{\theta}{2})^T \tag{15}
$$
令 $\theta = \theta + 2\pi$，则 $\boldsymbol{q} = (-cos\frac{\theta}{2}, -n_x\sin\frac{\theta}{2}, -n_ysin\frac{\theta}{2}, -n_zsin\frac{\theta}{2})^T = -\boldsymbol{q}$。即 &lt;strong&gt;$\boldsymbol{q}$ 和 $-\boldsymbol{q}$ 表示同一个旋转&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;令 $\boldsymbol{v} = (n_x, n_y, n_z)$，$\boldsymbol{w} = \theta\boldsymbol{v}$，则 $R = exp([\boldsymbol{w}]_{\times})$。&lt;/p&gt;
&lt;h3 id=&#34;4-旋转矩阵角轴表示法四元数之间的转换&#34;&gt;4. 旋转矩阵、角轴表示法、四元数之间的转换&lt;/h3&gt;
&lt;h4 id=&#34;41-旋转矩阵与四元数&#34;&gt;4.1 旋转矩阵与四元数&lt;/h4&gt;
&lt;h5 id=&#34;四元数到旋转矩阵的转换&#34;&gt;四元数到旋转矩阵的转换&lt;/h5&gt;
&lt;p&gt;通过 3.2 节，即可通过四元数计算得到旋转矩阵。&lt;/p&gt;
&lt;h5 id=&#34;旋转矩阵到四元数的转换&#34;&gt;旋转矩阵到四元数的转换&lt;/h5&gt;
&lt;p&gt;令旋转矩阵为
$$
R =
\left[
\begin{array}{ccc}
R_{11} &amp;amp; R_{12} &amp;amp; R_{13}\&lt;br&gt;
R_{21} &amp;amp; R_{22} &amp;amp; R_{23}\&lt;br&gt;
R_{31} &amp;amp; R_{32} &amp;amp; R_{33}
\end{array}
\right]
$$
则旋转矩阵到四元数的转换如下:
$q_0 = \frac{\sqrt{tr(R) + 1}}{2},\ q_1 = \frac{R_{23} - R_{32}}{4q_0},\ q_2 = \frac{R_{31} - R_{13}}{4q_0},\ q_3 = \frac{R_{12} - R{21}}{4q_0}$&lt;/p&gt;
&lt;h4 id=&#34;42-四元数与角轴表示法&#34;&gt;4.2 四元数与角轴表示法&lt;/h4&gt;
&lt;h5 id=&#34;四元数到角轴表示法的转换&#34;&gt;四元数到角轴表示法的转换&lt;/h5&gt;
&lt;p&gt;采用 3.2 节的符号表示，很容易得到
$$
\theta = 2arc cos\ q_0,\&lt;br&gt;
(n_x, n_y, n_z)^T = \frac{1}{sin\frac{\theta}{2}} (q_1, q_2, q_3)^T = \frac{1}{||\boldsymbol{n}||} (q_1, q_2, q_3)^T
$$&lt;/p&gt;
&lt;h5 id=&#34;角轴表示法到四元数的转换&#34;&gt;角轴表示法到四元数的转换&lt;/h5&gt;
&lt;p&gt;通过 3.2 节即可得到。&lt;/p&gt;
&lt;h4 id=&#34;43-旋转矩阵与角轴表示法的转换&#34;&gt;4.3 旋转矩阵与角轴表示法的转换&lt;/h4&gt;
&lt;h5 id=&#34;角轴表示法到旋转矩阵&#34;&gt;角轴表示法到旋转矩阵&lt;/h5&gt;
&lt;p&gt;很显然，通过指数映射，使用罗德里格斯公式就可以将角轴表示法变换到旋转矩阵&lt;/p&gt;
&lt;h5 id=&#34;旋转矩阵到角轴表示法&#34;&gt;旋转矩阵到角轴表示法&lt;/h5&gt;
&lt;p&gt;一般会先将旋转矩阵转换到四元数，再通过四元数转换到角轴表示法。&lt;/p&gt;
&lt;h3 id=&#34;5-罗德里格斯旋转公式-rodrigues-rotation-formula&#34;&gt;5. 罗德里格斯旋转公式 (Rodrigues&amp;rsquo; rotation formula)&lt;/h3&gt;
&lt;p&gt;和罗德里格斯公式不同(李代数到李群的指数映射)，&lt;code&gt;罗德里格斯旋转公式&lt;/code&gt;是用于对向量进行旋转的，即&lt;u&gt;给定空间中的一个三维点(具体形式是一个三维向量)，如何通过轴角表示法对三维点进行旋转&lt;/u&gt;。这个公式也被扩展用于计算指数映射，也就是罗德里格斯公式。罗德里格斯旋转公式可以通过以下公式计算得到:
$$
\boldsymbol{v}_{rot} = \boldsymbol{v}cos\theta + (\boldsymbol{k}\times \boldsymbol{v})sin\theta + \boldsymbol{k}(\boldsymbol{k} \cdot \boldsymbol{v})(1-cos\theta) \tag{16}
$$&lt;/p&gt;
&lt;h4 id=&#34;51-对三维点进行旋转&#34;&gt;5.1 对三维点进行旋转&lt;/h4&gt;
&lt;p&gt;实际中，使用轴角表示法对三维点进行旋转会分两种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$||\boldsymbol{w}||$ 相比0较大时。这个时候可以通过&lt;code&gt;罗德里格斯旋转公式&lt;/code&gt;计算&lt;/li&gt;
&lt;li&gt;$||\boldsymbol{w}||$ 相比0较小时。根据罗德里格斯公式，
$$
R = cos||\boldsymbol{w}||I + \frac{[\boldsymbol{w}]&lt;em&gt;{\times}}{||\boldsymbol{w}||} sin(||\boldsymbol{w}||) + \frac{[\boldsymbol{w}]&lt;/em&gt;{\times}^2}{||\boldsymbol{w}||^2}(1 - cos(||\boldsymbol{w}||))
$$
当$\boldsymbol{w}$较小时，$cos(||\boldsymbol{w}||) \approx 1, sin(||\boldsymbol{w}||) \approx ||\boldsymbol{w}||$。因此，$R \approx I + [\boldsymbol{w}]&lt;em&gt;{\times}$。于是，$R\boldsymbol{p} = \boldsymbol{p} + [\boldsymbol{w}]&lt;/em&gt;{\times} \boldsymbol{p}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;注： 对于李代数 $\boldsymbol{w} = \theta \boldsymbol{n}$，其中$\boldsymbol{n}$为单位转轴，因此 $||\boldsymbol{n}||^2 = 1$，于是$||\boldsymbol{w}||^2 = \theta^2 ||\boldsymbol{n}||^2 = \theta^2$。因此，有 $\theta = ||\boldsymbol{w}||$&lt;/em&gt;。&lt;/p&gt;
&lt;h4 id=&#34;52-ceres中的实现&#34;&gt;5.2 Ceres中的实现&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;template&amp;lt;typename T&amp;gt; inline
void AngleAxisRotatePoint(const T angle_axis[3], const T pt[3], T result[3]) {
  const T theta2 = DotProduct(angle_axis, angle_axis);
  if (theta2 &amp;gt; T(std::numeric_limits&amp;lt;double&amp;gt;::epsilon())) {
    // Away from zero, use the rodriguez formula
    //
    //   result = pt costheta +
    //            (w x pt) * sintheta +
    //            w (w . pt) (1 - costheta)
    //
    // We want to be careful to only evaluate the square root if the
    // norm of the angle_axis vector is greater than zero. Otherwise
    // we get a division by zero.
    //
    const T theta = sqrt(theta2);
    const T costheta = cos(theta);
    const T sintheta = sin(theta);
    const T theta_inverse = T(1.0) / theta;

    const T w[3] = { angle_axis[0] * theta_inverse,
                     angle_axis[1] * theta_inverse,
                     angle_axis[2] * theta_inverse };

    // Explicitly inlined evaluation of the cross product for
    // performance reasons.
    const T w_cross_pt[3] = { w[1] * pt[2] - w[2] * pt[1],
                              w[2] * pt[0] - w[0] * pt[2],
                              w[0] * pt[1] - w[1] * pt[0] };
    const T tmp =
        (w[0] * pt[0] + w[1] * pt[1] + w[2] * pt[2]) * (T(1.0) - costheta);

    result[0] = pt[0] * costheta + w_cross_pt[0] * sintheta + w[0] * tmp;
    result[1] = pt[1] * costheta + w_cross_pt[1] * sintheta + w[1] * tmp;
    result[2] = pt[2] * costheta + w_cross_pt[2] * sintheta + w[2] * tmp;
  } else {
    // Near zero, the first order Taylor approximation of the rotation
    // matrix R corresponding to a vector w and angle theta is
    //
    //   R = I + hat(w) * sin(theta)
    //
    // But sintheta ~ theta and theta * w = angle_axis, which gives us
    //
    //  R = I + hat(w)
    //
    // and actually performing multiplication with the point pt, gives us
    // R * pt = pt + w x pt.
    //
    // Switching to the Taylor expansion near zero provides meaningful
    // derivatives when evaluated using Jets.
    //
    // Explicitly inlined evaluation of the cross product for
    // performance reasons.
    const T w_cross_pt[3] = { angle_axis[1] * pt[2] - angle_axis[2] * pt[1],
                              angle_axis[2] * pt[0] - angle_axis[0] * pt[2],
                              angle_axis[0] * pt[1] - angle_axis[1] * pt[0] };

    result[0] = pt[0] + w_cross_pt[0];
    result[1] = pt[1] + w_cross_pt[1];
    result[2] = pt[2] + w_cross_pt[2];
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;6-so3-上的距离测量-distance-measure&#34;&gt;6. $SO(3)$ 上的距离测量 (Distance Measure)&lt;/h3&gt;
&lt;h5 id=&#34;1-bi-invariant-distance&#34;&gt;(1) Bi-invariant distance&lt;/h5&gt;
&lt;p&gt;如果对于所有的 $S$ 和 $R_i$，我们有 :
$$
d(SR_1, SR_2) = d(R_1, R_2) = d(R_1S, R_2S) \tag{17}
$$
那么这样的一个距离测量称为 &lt;code&gt;Bi-invariant&lt;/code&gt;.&lt;/p&gt;
&lt;h5 id=&#34;2-angular-distance-geodesic-distance&#34;&gt;(2) Angular Distance (Geodesic Distance)&lt;/h5&gt;
&lt;p&gt;定义 R 和 S 之间的 &lt;code&gt;angular distance&lt;/code&gt; 为旋转 $SR^T$ 的角度，并且处于区间 $[0, \pi]$ 里。因此，
$$
d(S, R) = d(SR^T, I) = ||log(SR^T)||_2 \tag{18}
$$
距离测量函数 $d(S, R)$ 和 $SR^T$ 的旋转角度相等。需要注意，我们可能会等价地写为 $R^TS$，$RS^T$，$S^TR$，因为这些都表示同一个旋转。&lt;/p&gt;
&lt;h5 id=&#34;3-chordal-distance&#34;&gt;(3) Chordal Distance&lt;/h5&gt;
&lt;p&gt;旋转 $R$ 和 $S$ 之间的 &lt;code&gt;chordal distance&lt;/code&gt; 定义为:
$$
d_{chord}(S, R) = ||S-R||_F \tag{19}
$$
其中，$||\cdot||_F$ 表示矩阵的 &lt;code&gt;Frobenius 范数&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;chordal distance&lt;/code&gt; 和 &lt;code&gt;angular distance&lt;/code&gt; 之间可以通过罗德里格斯公式关联起来:
$$
exp(\theta \boldsymbol{v}) = I + sin\theta\ [\boldsymbol{v}]&lt;em&gt;{\times} + (1-cos\theta)([\boldsymbol{v}]&lt;/em&gt;{\times})^2
$$
具体来讲，令 $SR^T = exp(\theta \boldsymbol{v})$，由于 $[\boldsymbol{v}]&lt;em&gt;{\times}$ 和 $([\boldsymbol{v}]&lt;/em&gt;{\times})^2$正交，且 $||[\boldsymbol{v}]&lt;em&gt;{\times}||^2_F = ||([\boldsymbol{v}]&lt;/em&gt;{\times})^2||^2_F = 2$，因此，我们有
$$
d_{chord}(S, R)^2 = ||S - R||^2 = ||SR^T - I||^2 = 2(sin^2\theta + (1-cos\theta)^2) = 8sin^2\frac{\theta}{2}
$$
因此，
$$
d_{chord}(S, R) = 2\sqrt{2} sin\frac{\theta}{2} \tag{20}
$$&lt;/p&gt;
&lt;h3 id=&#34;7-扰动模型对旋转求导&#34;&gt;7. 扰动模型对旋转求导&lt;/h3&gt;
&lt;p&gt;设左扰动 $\nabla R$ 对应的李代数为 $\boldsymbol{a}$。对 $\boldsymbol{a}$ 求导，有
$$
\frac{\delta(R\boldsymbol{p})}{\delta \boldsymbol{a}} = {\lim_{\boldsymbol{a} \to 0}} \frac{exp([\boldsymbol{a}]_{\times}) exp([\boldsymbol{a}]_{\times})\boldsymbol{p} - exp([\boldsymbol{a}]_{\times})\boldsymbol{p}}{\boldsymbol{a}} \&lt;br&gt;
= {\lim_{\boldsymbol{a} \to 0}} \frac{(1 + [\boldsymbol{a}]_{\times}) exp([\boldsymbol{a}]_{\times})\boldsymbol{p} - exp([\boldsymbol{a}]_{\times})\boldsymbol{p}}{\boldsymbol{a}}\&lt;br&gt;
= {\lim_{\boldsymbol{a} \to 0}} \frac{[\boldsymbol{a}]_{\times}R\boldsymbol{p}}{\boldsymbol{a}} = {\lim_{\boldsymbol{a} \to 0}} \frac{-[R\boldsymbol{p}]_{\times}\boldsymbol{a}}{\boldsymbol{a}} = -[R\boldsymbol{p}]_{\times}
$$&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;[1] 视觉SLAM十四讲 从理论到实践&lt;/li&gt;
&lt;li&gt;[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula&#34;&gt;https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] &lt;a href=&#34;https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation&#34;&gt;https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[4] Hartley, Richard, Trumpf, et al. Rotation Averaging[J]. International Journal of Computer Vision, 2013, 103(3):267-305.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>
